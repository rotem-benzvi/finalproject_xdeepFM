{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Ylo2SaVUq-jB"},"outputs":[],"source":["#!pip install -U deepctr-torch"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2046,"status":"ok","timestamp":1642775659010,"user":{"displayName":"רותם בן צבי","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16732271914870685259"},"user_tz":-120},"id":"0Kx0uREYWU4A","outputId":"4f651077-a937-459e-a788-c9328d0ca40b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'DeepCTR-Torch'...\n","remote: Enumerating objects: 1347, done.\u001b[K\n","remote: Counting objects: 100% (250/250), done.\u001b[K\n","remote: Compressing objects: 100% (137/137), done.\u001b[K\n","remote: Total 1347 (delta 148), reused 172 (delta 109), pack-reused 1097\u001b[K\n","Receiving objects: 100% (1347/1347), 4.97 MiB | 32.41 MiB/s, done.\n","Resolving deltas: 100% (857/857), done.\n"]}],"source":["#!git clone https://github.com/shenweichen/DeepCTR-Torch.git"]},{"cell_type":"markdown","metadata":{"id":"EGFlOp07FJZu"},"source":["## **1. Mount the drive and import all the libraries.**"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21098,"status":"ok","timestamp":1644999954862,"user":{"displayName":"רותם בן צבי","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16732271914870685259"},"user_tz":-120},"id":"j_DYm64B0S7m","outputId":"a7cba007-b92f-499f-94be-bd58e537cc20"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import  drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"RqCie-hktRlR","executionInfo":{"status":"ok","timestamp":1644999982636,"user_tz":-120,"elapsed":27781,"user":{"displayName":"רותם בן צבי","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16732271914870685259"}}},"outputs":[],"source":["import pandas as pd\n","from numpy import loadtxt\n","import matplotlib.pyplot as plt\n","import torch\n","import pickle\n","import json\n","from sklearn.metrics import log_loss, roc_auc_score\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n","\n","from drive.MyDrive.RCSYS_finalproject.DeepCTRTorch.deepctr_torch.inputs import SparseFeat, DenseFeat, get_feature_names\n","from drive.MyDrive.RCSYS_finalproject.DeepCTRTorch.deepctr_torch.models import *\n","from drive.MyDrive.RCSYS_finalproject.DeepCTRTorch.deepctr_torch.models.SExdeepfm import *\n","from drive.MyDrive.RCSYS_finalproject.DeepCTRTorch.deepctr_torch.inputs import VarLenSparseFeat"]},{"cell_type":"markdown","metadata":{"id":"-dCrs-IGFaeX"},"source":["## **2. Prepare the Criteo Dataset**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SJYyNawiawTJ"},"outputs":[],"source":["with open('/content/drive/MyDrive/RCSYS_finalproject/criteo_original/dnn_feature_columns_criteo.p', 'rb') as fp:\n","    dnn_feature_columns = pickle.load(fp)\n","\n","with open('/content/drive/MyDrive/RCSYS_finalproject/criteo_original/linear_feature_columns_criteo.p', 'rb') as fp:\n","    linear_feature_columns = pickle.load(fp)\n","\n","with open('/content/drive/MyDrive/RCSYS_finalproject/criteo_original/feature_names_criteo.p', 'rb') as fp:\n","    feature_names = pickle.load(fp)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"djodTHFrUyOm"},"outputs":[],"source":["#or we want to use the criteo full dataset\n","train = pd.read_pickle('/content/drive/MyDrive/RCSYS_finalproject/criteo_original/criteo_train.pkl')\n","test = pd.read_pickle('/content/drive/MyDrive/RCSYS_finalproject/criteo_original/criteo_test.pkl')"]},{"cell_type":"markdown","metadata":{"id":"Dnj-xRgDAuBr"},"source":["## **3. Or prepare the Avazu Dataset**"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"jriSB2_sNNUx","executionInfo":{"status":"ok","timestamp":1645000028656,"user_tz":-120,"elapsed":44478,"user":{"displayName":"רותם בן צבי","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16732271914870685259"}}},"outputs":[],"source":["#or we want to use the avazu full dataset\n","train = pd.read_pickle('/content/drive/MyDrive/RCSYS_finalproject/avazu/avazu_train.pkl')\n","test = pd.read_pickle('/content/drive/MyDrive/RCSYS_finalproject/avazu/avazu_test.pkl')"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"K_JXA-T8N8sf","executionInfo":{"status":"ok","timestamp":1645000030673,"user_tz":-120,"elapsed":2019,"user":{"displayName":"רותם בן צבי","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16732271914870685259"}}},"outputs":[],"source":["with open('/content/drive/MyDrive/RCSYS_finalproject/avazu/dnn_feature_columns_avazu.p', 'rb') as fp:\n","    dnn_feature_columns = pickle.load(fp)\n","\n","with open('/content/drive/MyDrive/RCSYS_finalproject/avazu/linear_feature_columns_avazu.p', 'rb') as fp:\n","    linear_feature_columns = pickle.load(fp)\n","\n","with open('/content/drive/MyDrive/RCSYS_finalproject/avazu/feature_names_avazu.p', 'rb') as fp:\n","    feature_names = pickle.load(fp)"]},{"cell_type":"markdown","metadata":{"id":"T5UO0cXMBmUG"},"source":["## **3. Start training**"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"5hUpgwoNGu8E","executionInfo":{"status":"ok","timestamp":1645000030674,"user_tz":-120,"elapsed":8,"user":{"displayName":"רותם בן צבי","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16732271914870685259"}}},"outputs":[],"source":["#choose the hyper parameters we want to use\n","# lr_list = [0.01, 0.001, 0.0001]\n","# batch_size_list = [256,512,1024,4096]\n","# lr_reg_list = [0.01, 0.001, 0.0001]\n","# epochs_list = [2, 3]\n","# model_name_list = ['DeepFM_avazu_original']\n","\n","lr_list = [0.01, 0.001, 0.0001]\n","batch_size_list = [4096]\n","lr_reg_list = [0.01, 0.001, 0.0001]\n","epochs_list = [3]\n","model_name_list = ['xDeepFM_avazu_original10']\n","\n","target = ['label']"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"xMDgPHv9Ajt3","executionInfo":{"status":"ok","timestamp":1645000030675,"user_tz":-120,"elapsed":8,"user":{"displayName":"רותם בן צבי","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16732271914870685259"}}},"outputs":[],"source":["def train_model(model_name, batch_size, epochs,lr, l2_reg_dnn, model_type_name='xdeepFM',attention_channels=21):\n","  if model_type_name == 'deepFM' or model_type_name == 'xdeepFM' or model_type_name == 'SExdeepFM':\n","    train_model_input = {name: train[name] for name in feature_names}\n","    test_model_input = {name: test[name] for name in feature_names}\n","\n","  #Define Model,train,predict and evaluate\n","  device = 'cpu'\n","  use_cuda = True\n","  if use_cuda and torch.cuda.is_available():\n","      print('cuda ready...')\n","      device = 'cuda:0'\n","  \n","  #xDeepFMmodel\n","  if model_type_name == 'xdeepFM':\n","    print('check')\n","    model = xDeepFM(linear_feature_columns=linear_feature_columns, dnn_feature_columns=dnn_feature_columns,\n","                    task='binary',\n","                    l2_reg_embedding=1e-5,l2_reg_dnn = l2_reg_dnn, dnn_dropout=0.5, device=device)\n","\n","  #SExDeepFMmodel\n","  if model_type_name == 'SExdeepFM':\n","    model = SExDeepFM(linear_feature_columns=linear_feature_columns, dnn_feature_columns=dnn_feature_columns,\n","                    task='binary',\n","                    l2_reg_embedding=1e-5,l2_reg_dnn = l2_reg_dnn, device=device,attention_channels = attention_channels)\n","  \n","  #DeepFMmodel\n","  if model_type_name == 'deepFM':\n","    model = DeepFM(linear_feature_columns=linear_feature_columns, dnn_feature_columns=dnn_feature_columns,task='binary',\n","                  l2_reg_embedding=1e-5,l2_reg_dnn = l2_reg_dnn,device='cuda')\n","  \n","  if model_type_name == 'DIN':\n","    x, y, feature_columns, behavior_feature_list = get_xy_fd_train()\n","    model = DIN(feature_columns, behavior_feature_list, device=device, att_weight_normalization=True)\n","\n","  if model_type_name == 'deepFM' or model_type_name == 'xdeepFM' or model_type_name == 'SExdeepFM':\n","    print('check')\n","    model.compile(\"adagrad\", \"binary_crossentropy\",\n","                  metrics=[\"binary_crossentropy\"], lr=lr,)\n","    history = model.fit(train_model_input,train[target].values, batch_size=batch_size, epochs=epochs,verbose=2,validation_split=0.15)\n","    #save_loss_history_and_figure(model_name,batch_size,epochs,lr,l2_reg_dnn)\n","    pred_ans = model.predict(test_model_input, batch_size)\n","    print(\"\")\n","    test_LogLoss = round(log_loss(test[target].values, pred_ans), 4)\n","    test_AUC = round(roc_auc_score(test[target].values, pred_ans), 4)\n","    print(\"test LogLoss\", test_LogLoss)\n","    print(\"test AUC\", test_AUC)\n","\n","    return history.history['loss'] , history.history['val_binary_crossentropy'], test_LogLoss, test_AUC\n","  \n","  else:\n","    model.compile('adagrad', 'binary_crossentropy',\n","              metrics=['binary_crossentropy'])\n","    history = model.fit(x, y, batch_size=128, epochs=100, verbose=2, validation_split=0.15)\n","    x, y, feature_columns, behavior_feature_list = get_xy_fd_test()\n","    pred_ans = model.predict(x, 128)\n","    print(\"\")\n","    test_LogLoss = round(log_loss(y, pred_ans), 4)\n","    test_AUC = round(roc_auc_score(y, pred_ans), 4)\n","    print(\"test LogLoss\", test_LogLoss)\n","    print(\"test AUC\", test_AUC)\n","    return history.history['loss'], test_LogLoss, test_AUC\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YhvHbJbfXGEs","outputId":"c25fa445-4300-4545-d4db-6f3642ce1024"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda ready...\n","check\n","check\n","cuda:0\n","Train on 21819182 samples, validate on 3850445 samples, 5327 steps per epoch\n","Epoch 1/3\n","2049s - loss:  0.3866 - binary_crossentropy:  0.3866 - val_binary_crossentropy:  0.3789\n","Epoch 2/3\n","2057s - loss:  0.3191 - binary_crossentropy:  0.3190 - val_binary_crossentropy:  0.4007\n","Epoch 3/3\n","2043s - loss:  0.2859 - binary_crossentropy:  0.2859 - val_binary_crossentropy:  0.4197\n","\n","test LogLoss 0.42\n","test AUC 0.7563\n","cuda ready...\n","check\n","check\n","cuda:0\n","Train on 21819182 samples, validate on 3850445 samples, 5327 steps per epoch\n","Epoch 1/3\n","2046s - loss:  0.3866 - binary_crossentropy:  0.3866 - val_binary_crossentropy:  0.3789\n","Epoch 2/3\n","2051s - loss:  0.3205 - binary_crossentropy:  0.3204 - val_binary_crossentropy:  0.4003\n"]}],"source":["results = pd.DataFrame(columns=['Model_name','Iterations','Batch_Size','Learning_Rate','DNN_Reg','test_AUC','test_LogLoss','Train_History','Val_History'])\n","model_type_name='xdeepFM'\n","\n","for model_name in model_name_list:\n","  for epochs in epochs_list:\n","    for batch_size in batch_size_list:\n","      for lr in lr_list:\n","        for l2_reg_dnn in lr_reg_list:\n","          dic = {'Model_name':model_name,'Iterations':epochs,'Batch_Size':batch_size,'Learning_Rate':lr,'DNN_Reg':l2_reg_dnn}\n","          if model_type_name== 'DIN':\n","            train_loss_history, test_LogLoss, test_AUC = train_model(model_name,batch_size,epochs,lr,l2_reg_dnn,model_type_name=model_type_name)\n","            dic['test_AUC'] = test_AUC\n","            dic['test_LogLoss'] = test_LogLoss\n","            dic['Train_History'] = train_loss_history\n","            results = results.append(dic,ignore_index=True)\n","            results.to_pickle('/content/drive/MyDrive/RCSYS_finalproject/results/results_'+ model_name + '.pkl')\n","          else: \n","            train_loss_history, val_loss_history, test_LogLoss, test_AUC = train_model(model_name,batch_size,epochs,lr,l2_reg_dnn,model_type_name=model_type_name)\n","            dic['test_AUC'] = test_AUC\n","            dic['test_LogLoss'] = test_LogLoss\n","            dic['Train_History'] = train_loss_history\n","            dic['Val_History'] = val_loss_history\n","            results = results.append(dic,ignore_index=True)\n","            results.to_pickle('/content/drive/MyDrive/RCSYS_finalproject/results/results_'+ model_name + '.pkl')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SfSWpvyl_Thn"},"outputs":[],"source":["#if we want to read the result dataframe\n","results = pd.read_pickle('/content/drive/MyDrive/RCSYS_finalproject/results/results_SExDeepFM_avazu.pkl')\n","results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JNMH1upyB9nV"},"outputs":[],"source":["def save_loss_history_and_figure(model_name,batch_size,epochs,lr,l2_reg_dnn):\n","  train_loss_file_name = \"/content/drive/MyDrive/RCSYS_finalproject/results/\" + \"train_loss_history_model_\" + model_name +'_bs_' + str(batch_size) + '_epochs_' + str(epochs) +'_lr_'+ str(lr)[2:] + '_reg_'+ str(l2_reg_dnn)[2:]\n","  val_loss_file_name = \"/content/drive/MyDrive/RCSYS_finalproject/results/\" + \"val_loss_history_model_\" + model_name +'_bs_' + str(batch_size) + '_epochs_' + str(epochs) +'_lr_'+ str(lr)[2:] + '_reg_'+ str(l2_reg_dnn)[2:]\n","  with open(train_loss_file_name, \"wb\") as fp:   #Pickling\n","    pickle.dump(history.history['loss'], fp)\n","  # with open(train_loss_file_name, \"rb\") as fp:   # Unpickling\n","  #   train_loss = pickle.load(fp)\n","  with open(val_loss_file_name, \"wb\") as fp:   #Pickling\n","    pickle.dump(history.history['val_binary_crossentropy'], fp)\n","  # with open(val_loss_file_name, \"rb\") as fp:   # Unpickling\n","  #   val_loss = pickle.load(fp)\n","\n","  save_loss_figure(history.history['loss'],history.history['val_binary_crossentropy'],model_name,batch_size,epochs,lr,l2_reg_dnn)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"085bgveXCtzR"},"outputs":[],"source":["def save_loss_figure(train_loss,val_loss,model_name,batch_size,epochs,lr,l2_reg_dnn):\n","  plt.figure(figsize=(12,5))\n","  plt.plot(train_loss)\n","  plt.plot(val_loss)\n","  plt.xticks(np.arange(len(train_loss)+1))\n","  plt.title('')\n","  plt.xlabel('Iterations')\n","  plt.ylabel('binary_crossentropy')\n","  plt.legend(['Train Loss', 'Validation Loss'])\n","  figure_name = \"/content/drive/MyDrive/RCSYS_finalproject/results/\" + \"figure_loss_\" + model_name +'_bs_' + str(batch_size) + '_epochs_' + str(epochs) +'_lr_'+ str(lr)[2:] + '_reg_' + str(l2_reg_dnn)[2:] + '.png'\n","  plt.savefig(figure_name)\n","  plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"RCSYS - final project.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}